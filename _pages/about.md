---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. Suspendisse condimentum, libero vel tempus mattis, risus risus vulputate libero, elementum fermentum mi neque vel nisl. Maecenas facilisis maximus dignissim. Curabitur mattis vulputate dui, tincidunt varius libero luctus eu. Mauris mauris nulla, scelerisque eget massa id, tincidunt congue felis. Sed convallis tempor ipsum rhoncus viverra. Pellentesque nulla orci, accumsan volutpat fringilla vitae, maximus sit amet tortor. Aliquam ultricies odio ut volutpat scelerisque. Donec nisl nisl, porttitor vitae pharetra quis, fringilla sed mi. Fusce pretium dolor ut aliquam consequat. Cras volutpat, tellus accumsan mattis molestie, nisl lacus tempus massa, nec malesuada tortor leo vel quam. Aliquam vel ex consectetur, vehicula leo nec, efficitur eros. Donec convallis non urna quis feugiat.

Tao (Eason) Yang is an Assistant Professor at Shanghai Jiao Tong University (SJTU). I am also a Research Fellow at the Shanghai Qi Zhi Institute and an Associate Professor at Shanghai Customs College (part-time). My research focuses on neural network acceleration (e.g., mixed-precision computing and SW/HW co-design.), in-memory computing, and brain-inspired neuromorphic computing.




My research interest includes neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>).


# üî• News
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2022.02*: &nbsp;üéâüéâ Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/500x300.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

- [T-BUS: Taming Bipartite Unstructured Sparsity for Energy-Efficient DNN Acceleration](https://ieeexplore.ieee.org/abstract/document/10818081) **ICCD 2024**  **(Acceptance Rate: 25%)**

  N Yang, **T Yang**, et al.

- [SpMMPlu-Pro: An enhanced compiler plug-in for efficient SpMM and sparsity propagation algorithm](https://ieeexplore.ieee.org/abstract/document/10818081) **TCAD 2024**  **(CCF Tier A)**

  S Huang\*, F Liu\*, **T Yang\***, Z Wang, N Yang, L Jiang

- [UM-PIM: DRAM-based PIM with Uniform & Shared Memory Space](https://ieeexplore.ieee.org/abstract/document/10818081) **ISCA 2024**  **(CCF Tier A)**

  Y Zhao, **T Yang**, et al.

- [Exploiting temporal-unrolled parallelism for energy-efficient snn acceleration](https://ieeexplore.ieee.org/abstract/document/10818081) **TPDS 2024**  **(CCF Tier A)**

  F Liu, **T Yang**, et al.

- [Sava: A Spatial-and Value-Aware Accelerator for Point Cloud Transformer](https://ieeexplore.ieee.org/abstract/document/10818081) **DATE 2024**  **(CCF Tier B)**

  X Liu, **T Yang**, et al.

- [Teas: Exploiting spiking activity for temporal-wise adaptive spiking neural networks](https://ieeexplore.ieee.org/abstract/document/10818081) **ASP-DAC 2024**  **(CCF Tier B)**

  F Liu, **T Yang**, et al.

- [PAAP-HD: PIM-Assisted Approximation for Efficient Hyper-Dimensional Computing](https://ieeexplore.ieee.org/abstract/document/10818081) **ASP-DAC 2024**  **(CCF Tier B)**

  F Liu, **T Yang**, et al.

- [A Point Cloud Video Recognition Acceleration Framework Based on Tempo-Spatial Information](https://ieeexplore.ieee.org/abstract/document/10818081) **TPDS 2024**  **(CCF Tier A)**

  Z Song, **T Yang**, et al.

- [SpMMPlu: A compiler plug-in with sparse IR for efficient sparse matrix multiplication](https://ieeexplore.ieee.org/abstract/document/10818081) **DAC 2023**  **(CCF Tier A)**

  **T Yang**,  Y Zhou, Q Tang, F Xu, H Ma, J Zhao, L Jiang

- [Hyperattack: An efficient attack framework for hyperdimensional computing](https://ieeexplore.ieee.org/abstract/document/10818081) **DAC 2023**  **(CCF Tier A)**

  F Liu, **T Yang**, et al.

- [Pimpr: Pim-based personalized recommendation with heterogeneous memory hierarchy](https://ieeexplore.ieee.org/abstract/document/10818081) **DATE 2023**  **(CCF Tier B)**

  T Yang, H Ma, Y Zhao, F Liu, Z He, X Sun, L Jiang

- [Randomize and match: Exploiting irregular sparsity for energy efficient processing in snns](https://ieeexplore.ieee.org/abstract/document/10818081) **ICCD 2023**  **(CCF Tier B)**

  F Liu, **T Yang**, et al.

- [Pim-dh: Reram-based processing-in-memory architecture for deep hashing acceleration](https://ieeexplore.ieee.org/abstract/document/10818081) **DAC 2022**  **(CCF Tier A)**

  F Liu, **T Yang**, et al.

- [Sato: spiking neural network acceleration via temporal-oriented dataflow and architecture](https://ieeexplore.ieee.org/abstract/document/10818081) **DAC 2022**  **(CCF Tier A)**

  F Liu, **T Yang**, et al.

- [DTATrans: Leveraging dynamic token-based quantization with accuracy compensation mechanism for efficient transformer architecture](https://ieeexplore.ieee.org/abstract/document/10818081) **TCAD 2022**  **(CCF Tier A)**

  **T Yang**, F Ma, X Li, F Liu, Y Zhao, Z He, L Jiang

- [PASGCN: An ReRAM-based PIM design for GCN with adaptively sparsified graphs](https://ieeexplore.ieee.org/abstract/document/10818081) **TCAD 2022**  **(CCF Tier A)**

  **T Yang**, D Li, F Ma, Z Song, Y Zhao, J Zhang, F Liu, L Jiang

- [SoBS-X: Squeeze-out bit sparsity for ReRAM-crossbar-based neural network accelerator](https://ieeexplore.ieee.org/abstract/document/10818081) **TCAD 2022**  **(CCF Tier A)**

  F Liu, **T Yang**, et al.

[Dtqatten: Leveraging dynamic token-based quantization for efficient attention architecture](https://ieeexplore.ieee.org/abstract/document/10818081) **DATE 2022**  **(CCF Tier B)**

  **T Yang**, D Li, Z Song, Y Zhao, F Liu, Z Wang, Z He, L Jiang

[IVQ: In-memory acceleration of DNN inference exploiting varied quantization](https://ieeexplore.ieee.org/abstract/document/10818081) **TCAD 2022**  **(CCF Tier A)**

  F Liu, **T Yang**, et al.

[PIMGCN: A ReRAM-based PIM design for graph convolutional network acceleration](https://ieeexplore.ieee.org/abstract/document/10818081) **DAC 2021**  **(CCF Tier A)**

  **T Yang**, D Li, Y Han, Y Zhao, F Liu, X Liang, Z He, L Jiang

[Sstdp: Supervised spike timing dependent plasticity for efficient spiking neural network training](https://ieeexplore.ieee.org/abstract/document/10818081) **Frontiers in Neuroscience 2021**

  F Liu, **T Yang**, et al.

[AdaptiveGCN: Efficient GCN through adaptively sparsifying graphs](https://ieeexplore.ieee.org/abstract/document/10818081) **CIKM 2021** **(CCF Tier B)**

  D Li, **T Yang**, et al.

[Sme: Reram-based sparse-multiplication-engine to squeeze-out bit sparsity of neural network](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)  **ICCD 2021**  **(Acceptance Rate: 25%)**

  F Liu, **T Yang**, et al.

[BISWSRBS: A winograd-based CNN accelerator with a fine-grained regular sparsity pattern and mixed precision quantization](https://ieeexplore.ieee.org/abstract/document/10818081) **TRETS 2021** **(CCF Tier B)**

  **T Yang**, Z He, T Kou, Q Li, Q Han, H Yu, F Liu, Y Liang, L Jiang

[IM3A: Boosting Deep Neural Network Efficiency via In-Memory Addressing-Assisted Acceleration](https://ieeexplore.ieee.org/abstract/document/10818081) **GLVLSI 2021** **(CCF Tier B)**

  F Liu, **T Yang**, et al.

[An FPGA-based neural network overlay for ADAS supporting multi-model and multi-mode](https://ieeexplore.ieee.org/abstract/document/10818081) **ISCAS 2021** **(CCF Tier C)**

  J Zhang, **T Yang**, et al.

[A Winograd-based CNN accelerator with a fine-grained regular sparsity pattern](https://ieeexplore.ieee.org/abstract/document/10818081) **FPL 2020** **(Acceptance Rate: 25%)**

  **T Yang**, Y Liao, J Shi, Y Liang, N Jing, L Jiang


[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>

- [T-BUS: Taming Bipartite Unstructured Sparsity for Energy-Efficient DNN Acceleration](https://github.com), A, B, C, **CVPR 2020**
- [SpMMPlu-Pro: An enhanced compiler plug-in for efficient SpMM and sparsity propagation algorithm](https://github.com), A, B, C, **CVPR 2020**
- [UM-PIM: DRAM-based PIM with Uniform & Shared Memory Space](https://github.com), A, B, C, **CVPR 2020**
- [Exploiting temporal-unrolled parallelism for energy-efficient snn acceleration](https://github.com), A, B, C, **CVPR 2020**
- [Sava: A Spatial-and Value-Aware Accelerator for Point Cloud Transformer](https://github.com), A, B, C, **CVPR 2020**
- [Teas: Exploiting spiking activity for temporal-wise adaptive spiking neural networks](https://github.com), A, B, C, **CVPR 2020**
- [PAAP-HD: PIM-Assisted Approximation for Efficient Hyper-Dimensional Computing](https://github.com), A, B, C, **CVPR 2020**
- [A Point Cloud Video Recognition Acceleration Framework Based on Tempo-Spatial Information](https://github.com), A, B, C, **CVPR 2020**
- [SpMMPlu: A compiler plug-in with sparse IR for efficient sparse matrix multiplication](https://github.com), A, B, C, **CVPR 2020**
- [Hyperattack: An efficient attack framework for hyperdimensional computing](https://github.com), A, B, C, **CVPR 2020**
- [Pimpr: Pim-based personalized recommendation with heterogeneous memory hierarchy](https://github.com), A, B, C, **CVPR 2020**
- [RePAST: A ReRAM-based PIM Accelerator for Second-order Training of DNN](https://github.com), A, B, C, **CVPR 2020**
- [Randomize and match: Exploiting irregular sparsity for energy efficient processing in snns](https://github.com), A, B, C, **CVPR 2020**
- [Pim-dh: Reram-based processing-in-memory architecture for deep hashing acceleration](https://github.com), A, B, C, **CVPR 2020**
- [Sato: spiking neural network acceleration via temporal-oriented dataflow and architecture](https://github.com), A, B, C, **CVPR 2020**
- [DTATrans: Leveraging dynamic token-based quantization with accuracy compensation mechanism for efficient transformer architecture](https://github.com), A, B, C, **CVPR 2020**
- [PASGCN: An ReRAM-based PIM design for GCN with adaptively sparsified graphs](https://github.com), A, B, C, **CVPR 2020**
- [SoBS-X: Squeeze-out bit sparsity for ReRAM-crossbar-based neural network accelerator](https://github.com), A, B, C, **CVPR 2020**
- [Dtqatten: Leveraging dynamic token-based quantization for efficient attention architecture](https://github.com), A, B, C, **CVPR 2020**
- [IVQ: In-memory acceleration of DNN inference exploiting varied quantization](https://github.com), A, B, C, **CVPR 2020**
- [PIMGCN: A ReRAM-based PIM design for graph convolutional network acceleration](https://github.com), A, B, C, **CVPR 2020**
- [Sstdp: Supervised spike timing dependent plasticity for efficient spiking neural network training](https://github.com), A, B, C, **CVPR 2020**
- [AdaptiveGCN: Efficient GCN through adaptively sparsifying graphs](https://github.com), A, B, C, **CVPR 2020**
- [Sme: Reram-based sparse-multiplication-engine to squeeze-out bit sparsity of neural network](https://github.com), A, B, C, **CVPR 2020**
- [BISWSRBS: A winograd-based CNN accelerator with a fine-grained regular sparsity pattern and mixed precision quantization](https://github.com), A, B, C, **CVPR 2020**
- [IM3A: Boosting Deep Neural Network Efficiency via In-Memory Addressing-Assisted Acceleration](https://github.com), A, B, C, **CVPR 2020**
- [An FPGA-based neural network overlay for ADAS supporting multi-model and multi-mode](https://github.com), A, B, C, **CVPR 2020**
- [A Winograd-based CNN accelerator with a fine-grained regular sparsity pattern](https://github.com), **FPL 2020**

**Tao Yang**, Y Liao, J Shi, Y Liang, N Jing, L Jiang

# üéñ Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üìñ Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# üíª Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.
